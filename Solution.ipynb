{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт библиотек\n",
    "import pandas as pd\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "from joblib import dump, load\n",
    "\n",
    "#Список имён файлов под features------------------\n",
    "files = [\"wagons_probeg_ownersip.parquet\", \"dislok_wagons.parquet\",\n",
    "         \"wag_params.parquet\", \"pr_rems.parquet\", \n",
    "         \"tr_rems.parquet\", \"kti_izm.parquet\",\n",
    "         \"freight_info.parquet\", \"stations.parquet\"]\n",
    "\n",
    "folders = ['train', 'test']\n",
    "relative_paths = [os.path.join(folder, file) for folder in folders for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(folder_name, files):\n",
    "    relative_paths = [os.path.join(folder_name, file) for file in files]\n",
    "    df_wagons_probeg_ownership, df_dislok_wagons, df_wag_params, df_pr_rems, df_tr_rems, df_kti_izm, df_freight_info, df_stations = list(map(pd.read_parquet, relative_paths))\n",
    "\n",
    "    #Не использую\n",
    "    df_freight_info = None\n",
    "    df_stations = None\n",
    "\n",
    "    #Избавляемся от лишних признаков в probeg\n",
    "    df1 = df_wagons_probeg_ownership.sort_values(by=['repdate', 'wagnum'], ascending=True)\n",
    "    df1 = df1.drop(columns = ['rod_id', 'month','ownership_type', \n",
    "                            'manage_type'])\n",
    "    probeg = df1\n",
    "    #print(probeg.head(5))\n",
    "    print(len(list(set(probeg['wagnum'].values))), probeg.shape) #Проверка на количество информации про вагоны 33977/33977 вагонов\n",
    "\n",
    "    #Избавляемся от лишних признаков в dislok\n",
    "    df2 = df_dislok_wagons.sort_values(by=['plan_date', 'wagnum'], ascending=True)\n",
    "    df2 = df2.drop(columns = ['st_id_send', 'id_road_send', 'isload', 'fr_id', \n",
    "                        'last_fr_id', 'distance', 'id_road_disl', 'kod_vrab',\n",
    "                        'date_pl_rem', 'st_id_dest', 'id_road_dest', 'ost_prob'])\n",
    "    dislok = df2\n",
    "    #print(dislok.head(5))\n",
    "    print(len(list(set(dislok['wagnum'].values))), dislok.shape) #Проверка на количество информации про вагоны 33977/33977 вагонов\n",
    "\n",
    "    df3 = df_wag_params.sort_values(by=['wagnum'], ascending=True)\n",
    "    df3 = df3.drop(columns = ['cnsi_volumek', 'ownertype', 'zavod_build', 'model', 'rod_id', 'date_iskl'])\n",
    "    df3 = df3.drop_duplicates(subset='wagnum', keep='last')\n",
    "    descr_wagon = df3\n",
    "    #print(descr_wagon.head(3))\n",
    "    print(len(list(set(descr_wagon['wagnum'].values))), descr_wagon.shape) #Проверка на количество информации про вагоны 33977/33977 вагонов\n",
    "\n",
    "    df4 = df_pr_rems.sort_values(by=['wagnum'], ascending=True)\n",
    "    df4 = df4.drop(columns = ['road_id_send', 'road_id_rem', 'st_id_send', 'st_id_rem', \n",
    "            'month', 'kod_vrab', 'rod_id', 'model'])\n",
    "    plans_rem = df4\n",
    "    #print(plans_rem.head(10))\n",
    "    print(len(list(set(plans_rem['wagnum'].values))), plans_rem.shape) #Проверка на количество информации про вагоны 10393/33977 вагонов\n",
    "    #Использовать этот df мы не будем так как содержит информацию не про все вагоны\n",
    "\n",
    "    df5 = df_tr_rems.sort_values(by=['wagnum'], ascending=True)\n",
    "    df5 = df5.drop(columns = ['kod_vrab', 'st_id_send', 'por_probeg', 'road_id_send'])\n",
    "    haved_rem = df5\n",
    "    #print(haved_rem.head(10))\n",
    "    print(len(list(set(haved_rem['wagnum'].values))), haved_rem.shape) #Проверка на количество информации про вагоны 17849/33977 вагонов\n",
    "    #Использовать этот df мы не будем так как содержит информацию не про все вагоны\n",
    "\n",
    "    df6 = df_kti_izm.sort_values(by=['operation_date_dttm', 'wagnum'], ascending=True)\n",
    "    df6 = df6.drop(columns = [])\n",
    "    kti = df6\n",
    "    #print(kti.head())\n",
    "    print(len(list(set(kti['wagnum'].values))), kti.shape) #Проверка на количество информации про вагоны 6829/33977 вагонов\n",
    "    #Использовать этот df мы не будем так как содержит информацию не про все вагоны\n",
    "\n",
    "    #Будем использовать информацию только ту, в которой описан каждый вагон\n",
    "    data = probeg.merge(dislok, left_on=['repdate', 'wagnum'], right_on=['plan_date', 'wagnum'])\\\n",
    "                .drop(columns=['plan_date'])\\\n",
    "                .merge(descr_wagon, left_on='wagnum', right_on='wagnum')\\\n",
    "                .sort_values(by=['wagnum', 'repdate'], ascending=True)\n",
    "    \n",
    "    print(len(list(set(data['wagnum'].values))), data.shape)\n",
    "    data.to_csv(\"data_\" + folder_name + \".csv\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33977 (6249857, 4)\n",
      "33977 (6250933, 4)\n",
      "33977 (33977, 14)\n",
      "10393 (10441, 3)\n",
      "17849 (48652, 13)\n",
      "6829 (67967, 19)\n",
      "33977 (6249316, 19)\n",
      "33708 (943810, 4)\n",
      "33701 (977304, 4)\n",
      "33977 (33977, 14)\n",
      "1589 (1591, 3)\n",
      "3922 (7500, 13)\n",
      "6686 (22428, 19)\n",
      "33701 (943591, 19)\n"
     ]
    }
   ],
   "source": [
    "Data_train = processing_data('train', files)\n",
    "Data_test = processing_data('test', files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Y(data, y_folder):\n",
    "    print('Загрузка данных...')\n",
    "    df_target = pd.read_csv(y_folder)\n",
    "    df_features = data\n",
    "\n",
    "    # Объединение данных\n",
    "    df_target['month'] = pd.to_datetime(df_target['month'])\n",
    "    df_features['repdate'] = pd.to_datetime(df_features['repdate'])\n",
    "    df_combined = pd.merge(df_target, df_features, left_on=['wagnum', 'month'], right_on=['wagnum', 'repdate'])\n",
    "    \n",
    "    print(\"Объём Y target:\", df_target.shape)\n",
    "    print(\"Объём features:\", df_features.shape)\n",
    "    print(\"Объём пересечения features и Y target\", df_combined.shape)\n",
    "    print(f'Модель сможет обработать: {df_combined.shape[0]/df_target.shape[0]}% от Y\\n',\n",
    "        f'Количество необработанных объектов: { df_target.shape[0] - df_combined.shape[0]}')\n",
    "    date_columns = ['repdate', 'month', 'date_kap', 'date_dep', 'date_build', 'srok_sl']\n",
    "\n",
    "    # Преобразование к типу datetime, если необходимо\n",
    "    df_combined[date_columns] = df_combined[date_columns].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "    # Преобразование в секунды\n",
    "    for col in date_columns:\n",
    "        df_combined[col] = (df_combined[col] - pd.Timestamp(\"1970-01-01\")).dt.total_seconds()\n",
    "\n",
    "    print('Подготовка данных...')\n",
    "\n",
    "    X = df_combined.drop(['target_month', 'target_day'], axis=1)\n",
    "    X = X.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "    y_10_days = df_combined['target_day']\n",
    "    y_month = df_combined['target_month']\n",
    "\n",
    "    #print(df_combined.head()\n",
    "    print('Выполнено!')\n",
    "    return X, y_10_days, y_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Объём Y target: (203853, 4)\n",
      "Объём features: (6249316, 19)\n",
      "Объём пересечения features и Y target (203844, 22)\n",
      "Модель сможет обработать: 0.9999558505393592% от Y\n",
      " Количество необработанных объектов: 9\n",
      "Подготовка данных...\n",
      "Выполнено!\n",
      "Загрузка данных...\n",
      "Объём Y target: (33708, 4)\n",
      "Объём features: (943591, 19)\n",
      "Объём пересечения features и Y target (33701, 22)\n",
      "Модель сможет обработать: 0.9997923341639967% от Y\n",
      " Количество необработанных объектов: 7\n",
      "Подготовка данных...\n",
      "Выполнено!\n"
     ]
    }
   ],
   "source": [
    "X_train, y_10_days_train, y_month_train = load_Y(Data_train, \"train\\\\y_train.csv\")\n",
    "X_test, y_10_days_test, y_month_test = load_Y(Data_test , \"test\\\\y_test.csv\")\n",
    "X_train, X_valid, y_10_days_train, y_10_days_valid, y_month_train, y_month_valid = train_test_split(X_train, y_10_days_train, y_month_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10_days = RandomForestClassifier()\n",
    "model_month = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model, X, Y):\n",
    "    model.fit(X, Y)\n",
    "     \n",
    "def model_check(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение моделей...\n",
      "Валидация моделей...\n",
      "Accuracy: 0.9836968963600091\n",
      "Accuracy: 0.9575988488079276\n"
     ]
    }
   ],
   "source": [
    "print('Обучение моделей...')\n",
    "model_fit(model_10_days, X_train, y_10_days_train)\n",
    "model_fit(model_month, X_train, y_month_train)\n",
    "\n",
    "print('Валидация моделей...')\n",
    "model_check(model_10_days, X_valid, y_10_days_valid)\n",
    "model_check(model_month, X_valid, y_month_valid)\n",
    "\n",
    "dump(model_month, 'modelM.joblib')\n",
    "dump(model_10_days, 'modelD.joblib')\n",
    "#Загрузка обученных на тренировке моделей\n",
    "modelM = load('modelM.joblib')\n",
    "modelD = load('modelD.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование моделей...\n",
      "Accuracy: 0.9837393549152844\n",
      "Accuracy: 0.9564107889973591\n"
     ]
    }
   ],
   "source": [
    "print('Тестирование моделей...')\n",
    "predictions_10_days = model_check(model_10_days, X_test, y_10_days_test)\n",
    "predictions_month = model_check(model_month, X_test, y_month_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit(model_10_days, X_test, y_10_days_test)\n",
    "model_fit(model_month, X_test, y_month_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение предсказаний\n",
    "df_X_selected = X_test[['wagnum', 'month']]\n",
    "\n",
    "df_X_selected.loc[:, 'month'] = pd.to_datetime(df_X_selected['month'], unit='s')# + pd.Timedelta(\"1970-01-01\")\n",
    "\n",
    "df_10_days_selected = pd.DataFrame(predictions_10_days, columns=['target_day'])[['target_day']]\n",
    "\n",
    "df_month_selected = pd.DataFrame(predictions_month, columns=['target_month'])[['target_month']]\n",
    "\n",
    "df_Y = pd.concat([df_X_selected, df_month_selected, df_10_days_selected], axis=1)\n",
    "\n",
    "#print(df_Y)\n",
    "df_Y.to_csv(\"Y_test_predict.csv\", index=False)\n",
    "#return calc_f1_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
